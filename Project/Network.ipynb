{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "from keras_metrics import KerasMetrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import decoding2\n",
    "import decoding_function as df\n",
    "from Files import nodes\n",
    "import os\n",
    "import utility as ut\n",
    "import livelossplot\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(verbs):\n",
    "    \"\"\"\n",
    "    Pipeline receives a list of verbs and predicts a conjugated form for them.\n",
    "    The prediction is saved in an output file.\n",
    "\n",
    "    :verbs type: list\n",
    "    :r type: string\n",
    "    \"\"\"\n",
    "    import coding_function as cf\n",
    "    from time import gmtime, strftime\n",
    "    import itertools\n",
    "    time = strftime(\"%Y-%m-%d_%H:%M:%S\", gmtime())\n",
    "    name = \"output_\" + time + \".txt\"\n",
    "\n",
    "    correct = {'#pega#': '#pEgu#', '#sega#': '#sEgu#', '#seka#': '#sEku#',\n",
    "               '#leva#': '#lEvu#', '#ora#': '#Oru#', '#mora#': '#mOru#',\n",
    "               '#posta#': '#pOtu#', '#joga#': '#jOgu#', '#sortia#': '#soiu#',\n",
    "               '#media#': '#meiu#', '#kompo#': '#koiu#', '#po#': '#poiu#', \n",
    "               '#menti#': '#mitu#', '#tosi#': '#tusu#', '#kobri#': \n",
    "               '#kuro#', '#faze#': '#fasu#', '#mata#': '#matu#', '#paga#': \n",
    "               '#pagu#', '#sai#': '#saiu#', '#bate#': '#batu#', '#kome#': \n",
    "               '#komu#','#nota#': '#nOta#','#soka#': '#sOku#','#loga#': '#lOga#',\n",
    "               '#limpa#': '#lipu#','#kasa#': '#kasu#'}\n",
    "\n",
    "#     f = open('Files/Results/'+ name, \"w\")\n",
    "#     f.write(\"train data set:\" + path + '\\n' + 'Results:\\n' + 'model name: ' + load + '\\n')\n",
    "    test_list = []\n",
    "    for i in verbs:\n",
    "        coding = cf.coding(i)\n",
    "        test_list.append(coding)\n",
    "    test_list = np.array(test_list)\n",
    "    prediction = model.predict(test_list)\n",
    "    sum = 0\n",
    "    for i,j in list(zip(verbs, prediction)):\n",
    "#         f.write('verb: '+ i + \", expected: \" + correct[i] + \", prediction: \" + \n",
    "#                 decoding2.decoding(j) + '\\n')\n",
    "        decoded = decoding2.decoding(j)\n",
    "        try: \n",
    "            print('input: '+ i + \", expected: \" + correct[i] + \", output: \" + \n",
    "                  decoded + '\\n')\n",
    "            if decoded == correct[i]:\n",
    "                sum = sum + 1 \n",
    "        except: \n",
    "            print('input: '+ i + \" -> output: \" + decoded + '\\n')\n",
    "        \n",
    "   \n",
    "    print(\"Accuracy (verbs): %.2f%%\" % (sum/len(verbs)*100 ))\n",
    "    scores = model.evaluate(X, Y)\n",
    "#     f.write(\"\\n%s: %.2f%% \\n%s: %.2f%% \\n%s: %.2f%%\" % (model.metrics_names[0], scores[1]*100,\n",
    "#                                                         model.metrics_names[1], scores[1]*100, \n",
    "#                                                         model.metrics_names[2], scores[2]*100,\n",
    "#                                                         model.metrics_names[3], scores[3]*100 ))\n",
    "    print(\"\\n%s: %.2f%% \\n%s: %.2f%% \\n%s: %.2f%% \\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100,\n",
    "                                                                   model.metrics_names[1], scores[1]*100, \n",
    "                                                                   model.metrics_names[2], scores[2]*100,\n",
    "                                                                   model.metrics_names[3], scores[3]*100 ))\n",
    "    \n",
    "    \n",
    "    #f.close()\n",
    "    return #print(\"\\nPredictions saved in the file: \" + name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = '../data/prop_55.csv' \n",
    "#path = '../data/prop_65.csv'\n",
    "#path = '../data/prop_75.csv'\n",
    "path = '../data/prop_85.csv'\n",
    "#path = '../data/prop_95.csv'\n",
    "#path = 'Files/50_50_morar.csv'\n",
    "X,Y = ut.load_data(path)\n",
    "batch = len(X)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Verify length of unique verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique verbs: 340 \n",
      "\n",
      "lenght of data set: 565\n"
     ]
    }
   ],
   "source": [
    "path = '../data/prop_65.csv'\n",
    "X,Y = ut.load_data(path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit Neural Net (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/390 [=>............................] - ETA: 1s\n",
      "loss: 1.42% \n",
      "fbeta_score: 99.14% \n",
      "recall: 98.80% \n",
      "precision: 99.49%\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Model\n",
    "model = Sequential()\n",
    "model.add(Dense(460, input_shape=(460,), activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 2. Compile model\n",
    "keras_metrics = KerasMetrics()\n",
    "model.compile( \n",
    "    optimizer='adam', \n",
    "    loss='mean_squared_error',\n",
    "    metrics = [ keras_metrics.fbeta_score,\n",
    "               keras_metrics.recall,\n",
    "               keras_metrics.precision]\n",
    "            )\n",
    "\n",
    "# 3. Fit model\n",
    "#stopper = EarlyStopping(monitor='loss', min_delta=0.00005, patience=50, verbose=1, mode='max')\n",
    "model.fit(X,Y,epochs = 400, batch_size=batch,verbose=False)#,callbacks= [stopper])\n",
    "\n",
    "# 4. Evaluate model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%% \\n%s: %.2f%% \\n%s: %.2f%% \\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100,\n",
    "                                                               model.metrics_names[1], scores[1]*100, \n",
    "                                                               model.metrics_names[2], scores[2]*100,\n",
    "                                                               model.metrics_names[3], scores[3]*100 ))\n",
    "\n",
    "# 5. Save model\n",
    "model.save('../data/prop_85')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (Or Load Trained Model)\n",
    "For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_metrics = KerasMetrics()\n",
    "model = load_model('../data/prop_75',custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Train existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model.fit(X,Y,epochs = 150, batch_size=batch,verbose=False,callbacks= [stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check Results\n",
    "Test the prediction for some verbs.\n",
    "\n",
    "pipeline(['#pega#','#sega#','#seka#','#leva#','#ora#','#mora#', '#posta#',\n",
    "          '#joga#','#sortia#','#media#','#kompo#','#po#','#tendi#','#jenti#',\n",
    "          '#menti#','#hendi#','#tosi#','#kobri#','#faze#','#mata#','#paga#',\n",
    "          '#sai#','#bate#','#kome#'])\n",
    "    \n",
    "\n",
    "|       \t|       \t| front \t| middle  \t| back    \t|\n",
    "|:-----:\t|-------\t|------:\t|---------\t|---------\t|\n",
    "|       \t|       \t| v/u   \t| v/u     \t| v/u     \t|\n",
    "|  **int**  | **stop**  | b/p   \t| d/t     \t| g/k     \t|\n",
    "|       \t| **nasal** | m/-   \t| n/-     \t| -       \t|\n",
    "| **cont**  | **fric**  | v/f   \t| z/s    \t| j/x   \t|\n",
    "|       \t| **liq**   | l/-   \t| r/-     \t| -/h     \t|\n",
    "| **vowel** | **high**  | e/i   \t| -       \t| o/u     \t|\n",
    "|       \t| **low**   | -/E   \t| -/a     \t| -/O     \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proporcao 55% Irregulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Model Name     | Test File     | Total Irregular Verbs | Total Verbs | Proportion | Epochs | Batch Size  |\n",
    "|:------------------:|---------------|----------------------:|-------------|------------|--------|-------------|\n",
    "| prop_55    | prop_55       |   209    |  464     |    55%     | 400    |  464         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique verbs: 341 \n",
      "\n",
      "lenght of data set: 452\n",
      "input: #pega#, expected: #pEgu#, output: #peju#\n",
      "\n",
      "input: #sega#, expected: #sEgu#, output: #segu#\n",
      "\n",
      "input: #seka#, expected: #sEku#, output: #seku#\n",
      "\n",
      "input: #leva#, expected: #lEvu#, output: #levu#\n",
      "\n",
      "input: #ora#, expected: #Oru#, output: #orru#\n",
      "\n",
      "input: #mora#, expected: #mOru#, output: #moru#\n",
      "\n",
      "input: #posta#, expected: #pOtu#, output: #pOtu#\n",
      "\n",
      "input: #joga#, expected: #jOgu#, output: #jogu#\n",
      "\n",
      "input: #sortia#, expected: #soiu#, output: #soiu#\n",
      "\n",
      "input: #media#, expected: #meiu#, output: #meiu#\n",
      "\n",
      "input: #kompo#, expected: #koiu#, output: #koiu#\n",
      "\n",
      "input: #po#, expected: #poiu#, output: #poiu#\n",
      "\n",
      "input: #menti#, expected: #mitu#, output: #mitu#\n",
      "\n",
      "input: #tosi#, expected: #tusu#, output: #tufu#\n",
      "\n",
      "input: #kobri#, expected: #kuro#, output: #koru#\n",
      "\n",
      "input: #faze#, expected: #fasu#, output: #fasu#\n",
      "\n",
      "input: #mata#, expected: #matu#, output: #matu#\n",
      "\n",
      "input: #paga#, expected: #pagu#, output: #pagu#\n",
      "\n",
      "input: #sai#, expected: #saiu#, output: #saiu#\n",
      "\n",
      "input: #bate#, expected: #batu#, output: #baiu#\n",
      "\n",
      "input: #kome#, expected: #komu#, output: #koeu#\n",
      "\n",
      "Accuracy (verbs): 47.62%\n",
      " 32/452 [=>............................] - ETA: 0s\n",
      "loss: 1.92% \n",
      "fbeta_score: 98.12% \n",
      "recall: 97.39% \n",
      "precision: 98.87%\n"
     ]
    }
   ],
   "source": [
    "path = '../data/prop_55.csv'\n",
    "X,Y = ut.load_data(path, verbose = True)\n",
    "keras_metrics = KerasMetrics()\n",
    "load = '../data/prop_55'\n",
    "model = load_model(load,custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})\n",
    "pipeline(['#pega#','#sega#','#seka#','#leva#','#ora#','#mora#', '#posta#',\n",
    "          '#joga#','#sortia#','#media#','#kompo#','#po#','#menti#','#tosi#',\n",
    "          '#kobri#','#faze#','#mata#','#paga#',\n",
    "          '#sai#','#bate#','#kome#'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proporcao 65% Irregulares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Model Name     | Test File     | Total Irregular Verbs | Total Verbs | Proportion | Epochs | Batch Size  | Total Unique Verbs\n",
    "|:------------------:|---------------|------------:|-------------|------------|--------|-------------|-------------|\n",
    "| prop_65     | prop_65       |      209        |  565        |    65%     | 400    |  565         |340|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: #pega#, expected: #pEgu#, output: #peju#\n",
      "\n",
      "input: #sega#, expected: #sEgu#, output: #segu#\n",
      "\n",
      "input: #seka#, expected: #sEku#, output: #seku#\n",
      "\n",
      "input: #leva#, expected: #lEvu#, output: #levu#\n",
      "\n",
      "input: #ora#, expected: #Oru#, output: #orru#\n",
      "\n",
      "input: #mora#, expected: #mOru#, output: #moru#\n",
      "\n",
      "input: #posta#, expected: #pOtu#, output: #bOtu#\n",
      "\n",
      "input: #joga#, expected: #jOgu#, output: #jogu#\n",
      "\n",
      "input: #sortia#, expected: #soiu#, output: #suiu#\n",
      "\n",
      "input: #media#, expected: #meiu#, output: #meiu#\n",
      "\n",
      "input: #kompo#, expected: #koiu#, output: #koiu#\n",
      "\n",
      "input: #po#, expected: #poiu#, output: #poiu#\n",
      "\n",
      "input: #menti#, expected: #mitu#, output: #mitu#\n",
      "\n",
      "input: #tosi#, expected: #tusu#, output: #tufu#\n",
      "\n",
      "input: #kobri#, expected: #kuro#, output: #koru#\n",
      "\n",
      "input: #faze#, expected: #fasu#, output: #fasu#\n",
      "\n",
      "input: #mata#, expected: #matu#, output: #matu#\n",
      "\n",
      "input: #paga#, expected: #pagu#, output: #pagu#\n",
      "\n",
      "input: #sai#, expected: #saiu#, output: #saiu#\n",
      "\n",
      "input: #bate#, expected: #batu#, output: #baiu#\n",
      "\n",
      "input: #kome#, expected: #komu#, output: #koeu#\n",
      "\n",
      "Accuracy (verbs): 38.10%\n",
      "544/565 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "loss: 1.87% \n",
      "fbeta_score: 98.10% \n",
      "recall: 97.45% \n",
      "precision: 98.77%\n"
     ]
    }
   ],
   "source": [
    "path = '../data/prop_65.csv'\n",
    "X,Y = ut.load_data(path)\n",
    "keras_metrics = KerasMetrics()\n",
    "load = '../data/testing'\n",
    "model = load_model(load,custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})\n",
    "pipeline(['#pega#','#sega#','#seka#','#leva#','#ora#','#mora#', '#posta#',\n",
    "          '#joga#','#sortia#','#media#','#kompo#','#po#','#menti#','#tosi#',\n",
    "          '#kobri#','#faze#','#mata#','#paga#',\n",
    "          '#sai#','#bate#','#kome#'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proporcao 75% Irregulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Model Name     | Test File     | Total Irregular Verbs | Total Verbs | Proportion | Epochs | Batch Size  |Total Unique Verbs|\n",
    "|:------------------:|---------------|----------------------:|-------------|------------|--------|-------------|----|\n",
    "| prop_75       | prop_75       |            300          |  388        |    75%     | 400   |  388         | 244|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique verbs: 244 \n",
      "\n",
      "lenght of data set: 388\n",
      "input: #pega#, expected: #pEgu#, output: #peku#\n",
      "\n",
      "input: #sega#, expected: #sEgu#, output: #segu#\n",
      "\n",
      "input: #seka#, expected: #sEku#, output: #siku#\n",
      "\n",
      "input: #leva#, expected: #lEvu#, output: #lezu#\n",
      "\n",
      "input: #ora#, expected: #Oru#, output: #orru#\n",
      "\n",
      "input: #mora#, expected: #mOru#, output: #muru#\n",
      "\n",
      "input: #posta#, expected: #pOtu#, output: #pOtu#\n",
      "\n",
      "input: #joga#, expected: #jOgu#, output: #jogu#\n",
      "\n",
      "input: #sortia#, expected: #soiu#, output: #suiu#\n",
      "\n",
      "input: #media#, expected: #meiu#, output: #meiu#\n",
      "\n",
      "input: #kompo#, expected: #koiu#, output: #koiu#\n",
      "\n",
      "input: #po#, expected: #poiu#, output: #poiu#\n",
      "\n",
      "input: #menti#, expected: #mitu#, output: #mitu#\n",
      "\n",
      "input: #tosi#, expected: #tusu#, output: #tufu#\n",
      "\n",
      "input: #kobri#, expected: #kuro#, output: #koru#\n",
      "\n",
      "input: #faze#, expected: #fasu#, output: #fasu#\n",
      "\n",
      "input: #mata#, expected: #matu#, output: #matu#\n",
      "\n",
      "input: #paga#, expected: #pagu#, output: #bagu#\n",
      "\n",
      "input: #sai#, expected: #saiu#, output: #saiu#\n",
      "\n",
      "input: #bate#, expected: #batu#, output: #bapu#\n",
      "\n",
      "input: #kome#, expected: #komu#, output: #koiu#\n",
      "\n",
      "Accuracy (verbs): 38.10%\n",
      "388/388 [==============================] - 0s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "loss: 1.57% \n",
      "fbeta_score: 98.82% \n",
      "recall: 98.43% \n",
      "precision: 99.22%\n"
     ]
    }
   ],
   "source": [
    "path = '../data/prop_75.csv'\n",
    "X,Y = ut.load_data(path, verbose = True)\n",
    "keras_metrics = KerasMetrics()\n",
    "load = '../data/prop_75'\n",
    "model = load_model(load, custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})\n",
    "pipeline(['#pega#','#sega#','#seka#','#leva#','#ora#','#mora#', '#posta#',\n",
    "          '#joga#','#sortia#','#media#','#kompo#','#po#','#menti#','#tosi#',\n",
    "          '#kobri#','#faze#','#mata#','#paga#',\n",
    "          '#sai#','#bate#','#kome#'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proporcao 85% Irregulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Model Name     | Test File     | Total Irregular Verbs | Total Verbs | Proportion | Epochs | Batch Size  | Total Unique Verbs|\n",
    "|:------------------:|---------------|----------------------:|-------------|------------|--------|-------------|---|\n",
    "| prop_85       | prop_85       |             340         |  390        |    85%     | 400   |  390         | 212|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique verbs: 212 \n",
      "\n",
      "lenght of data set: 390\n",
      "input: #pega#, expected: #pEgu#, output: #peku#\n",
      "\n",
      "input: #sega#, expected: #sEgu#, output: #sigu#\n",
      "\n",
      "input: #seka#, expected: #sEku#, output: #siku#\n",
      "\n",
      "input: #leva#, expected: #lEvu#, output: #levu#\n",
      "\n",
      "input: #ora#, expected: #Oru#, output: #orru#\n",
      "\n",
      "input: #mora#, expected: #mOru#, output: #muru#\n",
      "\n",
      "input: #posta#, expected: #pOtu#, output: #pOtu#\n",
      "\n",
      "input: #joga#, expected: #jOgu#, output: #jogu#\n",
      "\n",
      "input: #sortia#, expected: #soiu#, output: #suiu#\n",
      "\n",
      "input: #media#, expected: #meiu#, output: #meiu#\n",
      "\n",
      "input: #kompo#, expected: #koiu#, output: #koiu#\n",
      "\n",
      "input: #po#, expected: #poiu#, output: #poiu#\n",
      "\n",
      "input: #menti#, expected: #mitu#, output: #mitu#\n",
      "\n",
      "input: #tosi#, expected: #tusu#, output: #tupu#\n",
      "\n",
      "input: #kobri#, expected: #kuro#, output: #koru#\n",
      "\n",
      "input: #faze#, expected: #fasu#, output: #fasu#\n",
      "\n",
      "input: #mata#, expected: #matu#, output: #matu#\n",
      "\n",
      "input: #paga#, expected: #pagu#, output: #pagu#\n",
      "\n",
      "input: #sai#, expected: #saiu#, output: #saiu#\n",
      "\n",
      "input: #bate#, expected: #batu#, output: #baiu#\n",
      "\n",
      "input: #kome#, expected: #komu#, output: #koiu#\n",
      "\n",
      "Accuracy (verbs): 42.86%\n",
      " 32/390 [=>............................] - ETA: 1s\n",
      "loss: 1.42% \n",
      "fbeta_score: 99.14% \n",
      "recall: 98.80% \n",
      "precision: 99.49%\n"
     ]
    }
   ],
   "source": [
    "path = '../data/prop_85.csv'\n",
    "X,Y = ut.load_data(path, verbose = True)\n",
    "keras_metrics = KerasMetrics()\n",
    "load = '../data/prop_85'\n",
    "model = load_model(load,custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})\n",
    "pipeline(['#pega#','#sega#','#seka#','#leva#','#ora#','#mora#', '#posta#',\n",
    "          '#joga#','#sortia#','#media#','#kompo#','#po#','#menti#','#tosi#',\n",
    "          '#kobri#','#faze#','#mata#','#paga#',\n",
    "          '#sai#','#bate#','#kome#'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proporcao 95% Irregulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Model Name     | Test File     | Total Irregular Verbs | Total Verbs | Proportion | Epochs | Batch Size  | Total Unique Verbs|\n",
    "|:------------------:|---------------|----------------------:|-------------|------------|--------|-------------|---|\n",
    "| prop_95       | prop_95       |             380         |  395        |    95%     | 400   |  395         | 181|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique verbs: 181 \n",
      "\n",
      "lenght of data set: 395\n",
      "input: #pega#, expected: #pEgu#, output: #pEku#\n",
      "\n",
      "input: #sega#, expected: #sEgu#, output: #sigu#\n",
      "\n",
      "input: #seka#, expected: #sEku#, output: #siku#\n",
      "\n",
      "input: #leva#, expected: #lEvu#, output: #levu#\n",
      "\n",
      "input: #ora#, expected: #Oru#, output: #earu#\n",
      "\n",
      "input: #mora#, expected: #mOru#, output: #mEru#\n",
      "\n",
      "input: #posta#, expected: #pOtu#, output: #pOtu#\n",
      "\n",
      "input: #joga#, expected: #jOgu#, output: #xogu#\n",
      "\n",
      "input: #sortia#, expected: #soiu#, output: #soiu#\n",
      "\n",
      "input: #media#, expected: #meiu#, output: #meiu#\n",
      "\n",
      "input: #kompo#, expected: #koiu#, output: #koiu#\n",
      "\n",
      "input: #po#, expected: #poiu#, output: #poiu#\n",
      "\n",
      "input: #menti#, expected: #mitu#, output: #mitu#\n",
      "\n",
      "input: #tosi#, expected: #tusu#, output: #tutu#\n",
      "\n",
      "input: #kobri#, expected: #kuro#, output: #koru#\n",
      "\n",
      "input: #faze#, expected: #fasu#, output: #fasu#\n",
      "\n",
      "input: #mata#, expected: #matu#, output: #matu#\n",
      "\n",
      "input: #paga#, expected: #pagu#, output: #pagu#\n",
      "\n",
      "input: #sai#, expected: #saiu#, output: #saiu#\n",
      "\n",
      "input: #bate#, expected: #batu#, output: #baiu#\n",
      "\n",
      "input: #kome#, expected: #komu#, output: #koiu#\n",
      "\n",
      "Accuracy (verbs): 47.62%\n",
      " 32/395 [=>............................] - ETA: 0s\n",
      "loss: 1.22% \n",
      "fbeta_score: 99.42% \n",
      "recall: 99.20% \n",
      "precision: 99.63%\n"
     ]
    }
   ],
   "source": [
    "path = '../data/prop_95.csv'\n",
    "X,Y = ut.load_data(path, verbose = True)\n",
    "keras_metrics = KerasMetrics()\n",
    "load = '../data/prop_95'\n",
    "model = load_model(load, custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})\n",
    "pipeline(['#pega#','#sega#','#seka#','#leva#','#ora#','#mora#', '#posta#',\n",
    "          '#joga#','#sortia#','#media#','#kompo#','#po#','#menti#','#tosi#',\n",
    "          '#kobri#','#faze#','#mata#','#paga#',\n",
    "          '#sai#','#bate#','#kome#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: #tega# -> output: #tigu#\n",
      "\n",
      "Accuracy (verbs): 0.00%\n",
      " 32/192 [====>.........................] - ETA: 1s\n",
      "loss: 4.74% \n",
      "fbeta_score: 84.77% \n",
      "recall: 83.61% \n",
      "precision: 85.99%\n"
     ]
    }
   ],
   "source": [
    "keras_metrics = KerasMetrics()\n",
    "load = '../data/prop_95'\n",
    "model = load_model(load, custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})\n",
    "pipeline(['#tega#'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 50 - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: #nota#, expected: #nOta#, output: #dOtu#\n",
      "\n",
      "input: #soka#, expected: #sOku#, output: #sOku#\n",
      "\n",
      "input: #loga#, expected: #lOga#, output: #logu#\n",
      "\n",
      "input: #bate#, expected: #batu#, output: #batu#\n",
      "\n",
      "input: #limpa#, expected: #lipu#, output: #lipu#\n",
      "\n",
      "input: #kasa#, expected: #kasu#, output: #kasu#\n",
      "\n",
      "Accuracy (verbs): 66.67%\n",
      " 32/192 [====>.........................] - ETA: 1s\n",
      "loss: 0.73% \n",
      "fbeta_score: 99.87% \n",
      "recall: 99.75% \n",
      "precision: 99.99%\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../data/test_5050',custom_objects={'fbeta_score': keras_metrics.fbeta_score,\n",
    "                                                     'recall': keras_metrics.recall,\n",
    "                                                     'precision': keras_metrics.precision})\n",
    "pipeline(['#nota#','#soka#','#loga#','#bate#','#limpa#','#kasa#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import coding_function as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verbs = ['#posta#']\n",
    "test_list = []\n",
    "for i in verbs:\n",
    "    coding = cf.coding(i)\n",
    "    test_list.append(coding)\n",
    "test_list = np.array(test_list)\n",
    "prediction = model.predict(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01885734,  0.01925963,  0.20835543,  0.06943061,  0.20616981,\n",
       "         0.0709679 ,  0.04838099,  0.22368896,  0.16970563,  0.12240665,\n",
       "         0.0206362 ,  0.01205894,  0.91308624,  0.24333856,  0.68530637,\n",
       "         0.1774959 ,  0.01764845,  0.72755343,  0.33703929,  0.73652261,\n",
       "         0.03283259,  0.06553374,  0.04157919,  0.05008816,  0.0994515 ,\n",
       "         0.05351605,  0.06052314,  0.04473304,  0.07151185,  0.05618191,\n",
       "         0.02789558,  0.01436698,  0.02050743,  0.01129203,  0.06942753,\n",
       "         0.01098618,  0.05711168,  0.09250909,  0.00476367,  0.10850174,\n",
       "         0.04378862,  0.02906369,  0.28343081,  0.04388338,  0.26610306,\n",
       "         0.1870368 ,  0.0226121 ,  0.11979822,  0.15712078,  0.14190321,\n",
       "         0.87817395,  0.04864824,  0.05664408,  0.10420375,  0.90287876,\n",
       "         0.13406143,  0.92652106,  0.04734195,  0.916224  ,  0.1086485 ,\n",
       "         0.02241066,  0.90523285,  0.02660097,  0.09925672,  0.82048297,\n",
       "         0.03158227,  0.83003283,  0.0138406 ,  0.82197225,  0.08665778,\n",
       "         0.05624709,  0.07135151,  0.04626151,  0.04310372,  0.05342704,\n",
       "         0.01743226,  0.0646854 ,  0.02033214,  0.02857257,  0.06392817,\n",
       "         0.21806581,  0.10433639,  0.04915711,  0.03045056,  0.57583177,\n",
       "         0.02842332,  0.33064604,  0.0690212 ,  0.63244092,  0.02371524,\n",
       "         0.00839914,  0.02538023,  0.01904273,  0.00878486,  0.00944945,\n",
       "         0.00832413,  0.01879144,  0.0214697 ,  0.01075238,  0.02241805,\n",
       "         0.13802432,  0.17966433,  0.09011006,  0.18775618,  0.60956192,\n",
       "         0.07057817,  0.24224693,  0.2654255 ,  0.29949132,  0.20008869,\n",
       "         0.08789102,  0.02618507,  0.0393587 ,  0.03123341,  0.1430964 ,\n",
       "         0.10366924,  0.02554058,  0.06882392,  0.0309549 ,  0.06890314,\n",
       "         0.91852707,  0.82435745,  0.93855715,  0.10000953,  0.97174102,\n",
       "         0.12905803,  0.95705181,  0.89084262,  0.99526763,  0.80698544,\n",
       "         0.02898064,  0.05313815,  0.06133689,  0.04022538,  0.07016248,\n",
       "         0.06957193,  0.03650745,  0.05409649,  0.03833538,  0.04243788,\n",
       "         0.01558142,  0.63614774,  0.28764245,  0.05907762,  0.42750284,\n",
       "         0.11896875,  0.17653461,  0.29906642,  0.44785663,  0.05808876,\n",
       "         0.05101718,  0.03416453,  0.1166989 ,  0.03667271,  0.13561009,\n",
       "         0.06824975,  0.0577471 ,  0.04944289,  0.10553311,  0.10227519,\n",
       "         0.12891424,  0.03669637,  0.05756861,  0.08461005,  0.1440046 ,\n",
       "         0.12527393,  0.10347777,  0.04129879,  0.15000944,  0.0485073 ,\n",
       "         0.03458949,  0.03636364,  0.13863046,  0.06904524,  0.14187007,\n",
       "         0.07346322,  0.04118317,  0.51729023,  0.04427381,  0.31128296,\n",
       "         0.68009019,  0.02146056,  0.0289899 ,  0.00545026,  0.68018776,\n",
       "         0.01827169,  0.71547771,  0.03243591,  0.31581849,  0.03784964,\n",
       "         0.08608636,  0.04993911,  0.01162742,  0.01630008,  0.1096679 ,\n",
       "         0.00961782,  0.07078394,  0.01895771,  0.04868835,  0.03867152,\n",
       "         0.02626623,  0.54399943,  0.15820318,  0.07287442,  0.66790324,\n",
       "         0.02484803,  0.54126078,  0.18346117,  0.18211204,  0.2693373 ,\n",
       "         0.21267305,  0.16676889,  0.04693076,  0.06832252,  0.24412845,\n",
       "         0.05085504,  0.46720621,  0.0486838 ,  0.35719502,  0.02031069,\n",
       "         0.34256119,  0.34453136,  0.94523615,  0.24787572,  0.74885827,\n",
       "         0.19102064,  0.43678683,  0.75540674,  0.50487661,  0.3556    ,\n",
       "         0.13776499,  0.20215181,  0.04964295,  0.15236975,  0.09579124,\n",
       "         0.0628479 ,  0.21192627,  0.07683934,  0.05371622,  0.30705643,\n",
       "         0.34754908,  0.60321075,  0.14152248,  0.06287336,  0.80908757,\n",
       "         0.14748934,  0.8907873 ,  0.03345338,  0.7707451 ,  0.3211444 ,\n",
       "         0.02920493,  0.03896148,  0.01361489,  0.01852248,  0.07251446,\n",
       "         0.00909691,  0.03051258,  0.03185026,  0.03392068,  0.08138914,\n",
       "         0.02977944,  0.04182684,  0.90661395,  0.01939396,  0.9210794 ,\n",
       "         0.03825946,  0.01234346,  0.88851589,  0.90991884,  0.01775063,\n",
       "         0.02063378,  0.01403141,  0.06039995,  0.01735844,  0.0389927 ,\n",
       "         0.01945751,  0.01906138,  0.05858711,  0.05718805,  0.02773838,\n",
       "         0.02052629,  0.01752467,  0.05067197,  0.0157508 ,  0.06929158,\n",
       "         0.01868257,  0.01432541,  0.04930019,  0.05411847,  0.01966296,\n",
       "         0.0254264 ,  0.02714919,  0.04962422,  0.02526837,  0.05594934,\n",
       "         0.02382856,  0.01243746,  0.04949267,  0.05078098,  0.02082925,\n",
       "         0.01250864,  0.01800779,  0.95105267,  0.01125424,  0.94663095,\n",
       "         0.0370771 ,  0.01519523,  0.94707167,  0.95164156,  0.01996483,\n",
       "         0.02231196,  0.02869903,  0.06163804,  0.01703773,  0.06327341,\n",
       "         0.03409398,  0.01649821,  0.05048436,  0.06427703,  0.01599744,\n",
       "         0.01510236,  0.03986111,  0.92474532,  0.02439696,  0.90537196,\n",
       "         0.01246644,  0.02355465,  0.87619019,  0.9208554 ,  0.02652102,\n",
       "         0.01431737,  0.01481656,  0.0931914 ,  0.01443999,  0.08756603,\n",
       "         0.00989676,  0.02772097,  0.08703662,  0.10886332,  0.019939  ,\n",
       "         0.02515291,  0.02497203,  0.97604162,  0.03023048,  0.97680658,\n",
       "         0.02095667,  0.0260242 ,  0.97489649,  0.97583514,  0.01979408,\n",
       "         0.01870665,  0.03011655,  0.02191341,  0.01456833,  0.02749828,\n",
       "         0.02508157,  0.01444691,  0.02506104,  0.02543477,  0.02026419,\n",
       "         0.01702186,  0.03620421,  0.89275366,  0.13111068,  0.69617444,\n",
       "         0.08265411,  0.03909421,  0.77754653,  0.34968197,  0.52599448,\n",
       "         0.01746698,  0.02179792,  0.07903472,  0.02368145,  0.07733696,\n",
       "         0.02619044,  0.01478825,  0.13933548,  0.0616624 ,  0.03630221,\n",
       "         0.07426108,  0.04792669,  0.02502617,  0.13387255,  0.02880555,\n",
       "         0.05536791,  0.09033775,  0.02353082,  0.02433033,  0.06423365,\n",
       "         0.05005853,  0.02854306,  0.27957189,  0.11341244,  0.2268264 ,\n",
       "         0.11835743,  0.07555016,  0.19551869,  0.08901879,  0.18281992,\n",
       "         0.02207642,  0.01628569,  0.72022367,  0.23265493,  0.39434049,\n",
       "         0.08680271,  0.02677183,  0.65611869,  0.31527933,  0.32510731,\n",
       "         0.09236114,  0.0411019 ,  0.74519527,  0.36402342,  0.4157365 ,\n",
       "         0.13675454,  0.05991996,  0.54883939,  0.61429453,  0.31959623,\n",
       "         0.02287645,  0.00889764,  0.25893179,  0.04729389,  0.1421283 ,\n",
       "         0.0467529 ,  0.01631898,  0.17144871,  0.02073561,  0.24901198,\n",
       "         0.01395311,  0.02929176,  0.06552632,  0.0401146 ,  0.09856965,\n",
       "         0.02055683,  0.02203991,  0.05949004,  0.02076477,  0.05402106,\n",
       "         0.04977645,  0.057404  ,  0.92004222,  0.42112628,  0.72413588,\n",
       "         0.14079891,  0.04569798,  0.81161392,  0.23767449,  0.57179755,\n",
       "         0.0299603 ,  0.01648212,  0.03121879,  0.03670406,  0.03752997,\n",
       "         0.04975127,  0.0534329 ,  0.05722837,  0.02923216,  0.09853445]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
